{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topicos de estudo para a AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fases de um projeto de machine learning versus etapas do CRISP-DM\n",
    "\n",
    "<img src=\"crisp.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória\n",
    "\n",
    "- O que fazer **antes** da separação treino-teste e o que fazer **depois**\n",
    "\n",
    "    - Antes: analise da natureza global das variaveis, independentemente uma das outras\n",
    "\n",
    "        - Só coisa \"ingênua\", que não leva diretamente a construção de modelos\n",
    "\n",
    "        - Análise de anomalias: valores faltantes, outliers, erros grosseiros\n",
    "\n",
    "        - Variáveis contínuas:\n",
    "        \n",
    "            - Medidas descritivas (média, mediana, desvio padrão, etc)\n",
    "\n",
    "            - Histogramas\n",
    "\n",
    "        - Variáveis categóricas:\n",
    "\n",
    "            - Frequências (`value_counts`)\n",
    "\n",
    "    - Separação treino-teste:\n",
    "\n",
    "        - Nada especial, só lembre de fixar o `random_state`\n",
    "\n",
    "            > ```Python\n",
    "            > \n",
    "            > from sklearn.model_selection import train_test_split\n",
    "            > \n",
    "            > SEED = 42\n",
    "            > \n",
    "            > X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "            > \n",
    "            > ```\n",
    "\n",
    "    - Depois: tá liberado, mas só no conjunto de treino\n",
    "\n",
    "        - Analisar dependencias entre variaveis, e entre elas e o target\n",
    "\n",
    "        - Contínua versus contínua:\n",
    "\n",
    "            - Medidas de correlação (Pearson, Spearman, Kendall)\n",
    "\n",
    "            - Gráficos de espalhamento (*scatter plots*)\n",
    "\n",
    "        - Categórica versus categórica\n",
    "\n",
    "            - Teste de independencia: teste qui-quadrado de Pearson (*chi-square*). **Não foi visto em aula, não se preocupe.**\n",
    "\n",
    "            - Tabela de contingência (`cross_tab`)\n",
    "\n",
    "        - Categórica versus contínua\n",
    "\n",
    "            - Boxplot da contínua para cada categoria\n",
    "\n",
    "            - Teste de Kolmogorov-Smirnov entre valores da variável contínua para pares de categorias. **Não foi visto em aula, não se preocupe.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data = load_wine(as_frame=True)\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.data\n",
    "dataset['target'] = data.target.astype('category')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset \\\n",
    "    .select_dtypes(include='float64') \\\n",
    "    .describe() \\\n",
    "    .round(2) \\\n",
    "    .transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset \\\n",
    "    .select_dtypes(include='category') \\\n",
    "    .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "dataset_train, dataset_test = train_test_split(\n",
    "    dataset,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape, dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "\n",
    "seaborn.pairplot(dataset_train, hue='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"transformadores.png\" width=70%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Exemplo de transformador\n",
    "X_train = dataset_train.drop(columns='target')\n",
    "y_train = dataset_train['target']\n",
    "\n",
    "X_test = dataset_test.drop(columns='target')\n",
    "y_test = dataset_test['target']\n",
    "\n",
    "X_train.describe().round(2).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cria o transformador.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Treina o transformador.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Aplica o transformador.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    X_train_scaled,\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index,\n",
    ")\n",
    "\n",
    "X_train_scaled.describe().round(2).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo coisa proibida só para ilustrar o StandardScaler.\n",
    "# Isso é proibido AGORA, antes da modelagem. Mas DEPOIS da escolha de modelo,\n",
    "# pode ser feito sem problemas.\n",
    "X_test.describe().round(2).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    X_test_scaled,\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index,\n",
    ")\n",
    "\n",
    "X_test_scaled.describe().round(2).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines de transformação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pipeline.png\" width=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para quem olha \"de fora\", uma *pipeline* se parece com um transformador e nada mais! Podemos treiná-lo com o método `fit`:\n",
    "\n",
    "<img src=\"pipeline_transform_train.png\" width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o que acontece \"por trás das cortinas\"? Deixa que o *Scikit-Learn* cuida de tudo para você! Mas, para nosso entendimento, eis o que acontece:\n",
    "\n",
    "<img src=\"pipeline_transform_train_internals.png\" width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que o pipeline está treinado, podemos usá-lo para fazer transformações de dados, como um transformer qualquer!\n",
    "\n",
    "<img src=\"pipeline_transform_apply.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, por dentro, o que acontece? O *Scikit-Learn* vai chamar cada transformador, um por vez, em sequência:\n",
    "\n",
    "<img src=\"pipeline_transform_apply_internals.png\" width=50%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "# Cria a pipeline.\n",
    "pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina a pipeline.\n",
    "pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas na saida do PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Colunas de grau 1: as 13 features originais.\n",
    "n_deg_1 = 13\n",
    "\n",
    "# Colunas de grau 2 com features diferentes: \n",
    "# combinações de 2 features originais.\n",
    "n_deg_2_diff = 13 * (13 - 1) // 2  # 13 escolha 2\n",
    "\n",
    "# Colunas de grau 2 com features iguais:\n",
    "# cada coluna original ao quadrado.\n",
    "n_deg_2_same = 13\n",
    "\n",
    "n_cols_total = n_deg_1 + n_deg_2_diff + n_deg_2_same\n",
    "\n",
    "n_cols_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines preditoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toda *pipeline* é feita de uma sequência de estágios *transformadores*, e o último estágio pode ser um *transformador* ou um *modelo preditivo*.\n",
    "\n",
    "- ***Pipeline*** **transformadora**:\n",
    "\n",
    "Quando o último estágio é um *transformador* (como no exemplo anterior), a *pipeline* atua como um *transformador*\n",
    "\n",
    "- ***Pipeline*** **preditora**:\n",
    "\n",
    "Quando o último estágio é um *modelo preditivo*, a *pipeline* atua como um *modelo preditivo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pipeline_predict.png\" width=50%/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamos a *pipeline* preditora do mesmo jeito que treinamos modelos:\n",
    "\n",
    "<img src=\"pipeline_predict_train.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Por trás dos panos\":\n",
    "\n",
    "<img src=\"pipeline_predict_train_internals.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer predições, use como se fosse um modelo qualquer!\n",
    "\n",
    "<img src=\"pipeline_predict_apply.png\" width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, o que acontece \"por dentro\":\n",
    "\n",
    "<img src=\"pipeline_predict_apply_internals.png\" width=90%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ColumnTransformer`, `Pipeline` e transformadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ```Python\n",
    "> geo_cols = [\n",
    ">     'longitude',\n",
    ">     'latitude',\n",
    "> ]\n",
    "> \n",
    "> numerical_cols = [\n",
    ">     'housing_median_age',\n",
    ">     'log_households',\n",
    ">     'log_median_income',\n",
    ">     'log_rooms_per_household',\n",
    ">     'log_population_per_household',\n",
    ">     'log_bedrooms_per_room',\n",
    "> ]\n",
    "> \n",
    "> categorical_cols = [\n",
    ">     'ocean_proximity',\n",
    "> ]\n",
    "> \n",
    "> geo_pipeline = Pipeline([\n",
    ">     ('imputer', SimpleImputer(strategy='median')),\n",
    ">     ('cluster', KMeans(n_clusters=50)),\n",
    "> ])\n",
    "> \n",
    "> num_pipeline = Pipeline([\n",
    ">     ('imputer', SimpleImputer(strategy='median')),\n",
    ">     ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
    ">     ('scaler', StandardScaler()),\n",
    "> ])\n",
    "> \n",
    "> cat_pipeline = Pipeline([\n",
    ">     ('encoder', OneHotEncoder(sparse_output=False)),\n",
    "> ])\n",
    "> \n",
    "> preprocessing_pipe = ColumnTransformer(\n",
    ">     transformers=[\n",
    ">         ('geo', geo_pipeline, geo_cols),\n",
    ">         ('num', num_pipeline, numerical_cols),\n",
    ">         ('cat', cat_pipeline, categorical_cols),\n",
    ">     ],\n",
    ">     remainder='passthrough',\n",
    "> )\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"column_transformer.png\" width=100%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão simples: train-test-val split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão mais sofisticada: validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparâmetros\n",
    "\n",
    "- `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão\n",
    "\n",
    "- Medidas de desempenho: MSE, RMSE\n",
    "\n",
    "- Análise de erros:\n",
    "\n",
    "    - Resíduos\n",
    "\n",
    "- Modelo trivial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classificação binária e multiclasse\n",
    "\n",
    "    - Classificador trivial\n",
    "\n",
    "De resto, só classificação binária.\n",
    "\n",
    "- Medidas de desempenho:\n",
    "\n",
    "    - acurácia\n",
    "\n",
    "    - Precision e recall\n",
    "\n",
    "        - trade-off precision vs. recall\n",
    "\n",
    "        - Curva precision-recall, `cross_val_predict`\n",
    "\n",
    "        - métrica F1\n",
    "\n",
    "    - Sensibility e specificity\n",
    "\n",
    "        - trade-off sensibility vs. specificity\n",
    "\n",
    "        - Curva ROC, área sob a curva ROC (AUC ou AUROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo linear\n",
    "\n",
    "- Definição\n",
    "\n",
    "- Explicação intuitiva de porque não podemos ter *features colineares*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
